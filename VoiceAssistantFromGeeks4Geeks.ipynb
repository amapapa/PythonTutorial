{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.5"
    },
    "colab": {
      "name": "VoiceAssistantFromGeeks4Geeks.ipynb",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/amapapa/PythonTutorial/blob/main/VoiceAssistantFromGeeks4Geeks.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uLgVU0MvDVJ-"
      },
      "source": [
        "# ! pip install -r requirements.txt\n",
        "\n",
        "# https://towardsdatascience.com/how-to-build-your-own-ai-personal-assistant-using-python-f57247b4494b"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p20sN2RkDVKI"
      },
      "source": [
        "import speech_recognition as sr\n",
        "import pyttsx3\n",
        "import datetime\n",
        "import wikipedia\n",
        "import webbrowser\n",
        "import os\n",
        "import time\n",
        "import subprocess\n",
        "from ecapture import ecapture as ec\n",
        "import wolframalpha\n",
        "import json\n",
        "import requests\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mhQgxOu0DVKP"
      },
      "source": [
        "\n",
        "## Speech engine\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E0Gh7cgWDVKQ",
        "outputId": "a4d2b0cc-1ae8-4482-8c34-471162ac5bc9"
      },
      "source": [
        "'''Setting up the speech engine:\n",
        "   The pyttsx3 module is stored in a variable name engine.\n",
        "   Sapi5 is a Microsoft Text to speech engine used for voice recognition.\n",
        "   The voice Id can be set as either 0 or 1'''\n",
        "\n",
        "# 0 indicates Male voice\n",
        "# 1 indicates Female voice\n",
        "\n",
        "\n",
        "engine=pyttsx3.init('sapi5')\n",
        "voices=engine.getProperty('voices')\n",
        "# engine.setProperty('voice', voices[1].id)\n",
        "engine.setProperty('voice', voices[1].id)\n",
        "\n",
        "rate = engine.getProperty('rate')   # getting details of current speaking rate\n",
        "print (rate)                        #printing current voice rate\n",
        "engine.setProperty('rate', 155)     # setting up new voice rate"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "125\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9mnlhHiRDVKX"
      },
      "source": [
        "## Text to speech \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n_Z1jKduDVKX"
      },
      "source": [
        "def speak(text):\n",
        "    engine.say(text)\n",
        "    engine.runAndWait()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ruoeRRrJDVKc"
      },
      "source": [
        "## Test to see how the text to speech works in this context\n",
        "speak(\"This is real good work : Amar. I am impressed \")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "StkhTk7fDVKf"
      },
      "source": [
        "## Greeting the user - Voice Assistant"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3_uHMmp5DVKg"
      },
      "source": [
        "def wishMe():\n",
        "    hour = datetime.datetime.now().hour\n",
        "    if hour>=0 and hour<12:\n",
        "        speak(\"Hello Amar, Good Morning\")\n",
        "        print(\"Hello Amar, Good Morning\")\n",
        "    elif hour >=12 and hour <18:\n",
        "        speak(\"Hello Amar, Good Afternoon\")\n",
        "        print(\"Hello Amar, Good Afternoon\")\n",
        "    else:\n",
        "        speak(\"Hello Amar, Good evening\")\n",
        "        print(\"Hello Amar, Good evening\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sHK4T-biDVKi",
        "outputId": "9915e874-a93e-462f-8e7b-3039607584d8"
      },
      "source": [
        "wishMe()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Hello Amar, Good Morning\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "okqbeyisDVKn"
      },
      "source": [
        "## Setting up the command function for the AI assistant\n",
        "The Main task of Speech Recognition \n",
        "</p>This is similar to \"Hello Google\" or \"Hey Siri\""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z79Z5y0sDVKn",
        "outputId": "60d1ee00-27c7-4700-e1e6-ddeac4c2caac"
      },
      "source": [
        "def takeCommand():\n",
        "    r=sr.Recognizer()\n",
        "    with sr.Microphone() as source:\n",
        "        print(\"Listening...\")\n",
        "        print(type(source))\n",
        "        audio=r.listen(source)\n",
        "\n",
        "        try:\n",
        "            statement=r.recognize_google(audio,language='en-in')\n",
        "            print(f\"user said:{statement}\\n\")\n",
        "\n",
        "        except Exception as e:\n",
        "            speak(\"Pardon me, please say that again\")\n",
        "            return \"None\"\n",
        "        return statement\n",
        "\n",
        "print(\"Loading your AI personal assistant Trumph\")\n",
        "speak(\"Loading your AI personal assistant Trumph\")\n",
        "wishMe()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loading your AI personal assistant Trumph\n",
            "Hello Amar, Good Morning\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rr3OIBhnDVKq",
        "outputId": "d8df0c02-5424-43c7-b2bf-20d6b2823aeb"
      },
      "source": [
        "takeCommand()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Listening...\n",
            "<class 'speech_recognition.Microphone'>\n",
            "user said:check\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'check'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 104
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MTgQX7xADVKs",
        "outputId": "6f8ba4b3-d7c0-4cb8-9b95-a1e0cb974e69"
      },
      "source": [
        "if __name__=='__main__':\n",
        "\n",
        "\n",
        "    while True:\n",
        "        speak(\"Tell me how can I help you now?\")\n",
        "        statement = takeCommand().lower()\n",
        "        if statement==0:\n",
        "            continue\n",
        "        if \"good bye\" in statement or \"ok bye\" in statement or \"stop\" in statement:\n",
        "            speak('your personal assistant G-one is shutting down,Good bye')\n",
        "            print('your personal assistant G-one is shutting down,Good bye')\n",
        "            break\n",
        "        if 'wikipedia' in statement:\n",
        "            speak('Searching Wikipedia...')\n",
        "            statement =statement.replace(\"wikipedia\", \"\")\n",
        "            results = wikipedia.summary(statement, sentences=3)\n",
        "            speak(\"According to Wikipedia\")\n",
        "            print(results)\n",
        "            speak(results)\n",
        "        elif 'open youtube' in statement:\n",
        "            webbrowser.open_new_tab(\"https://www.youtube.com\")\n",
        "            speak(\"youtube is open now\")\n",
        "            time.sleep(5)\n",
        "\n",
        "        elif 'open google' in statement:\n",
        "            webbrowser.open_new_tab(\"https://www.google.com\")\n",
        "            speak(\"Google chrome is open now\")\n",
        "            time.sleep(5)\n",
        "\n",
        "        elif 'open gmail' in statement:\n",
        "            webbrowser.open_new_tab(\"gmail.com\")\n",
        "            speak(\"Google Mail open now\")\n",
        "            time.sleep(5)\n",
        "        elif 'time' in statement:\n",
        "            strTime=datetime.datetime.now().strftime(\"%H:%M:%S\")\n",
        "            speak(f\"the time is {strTime}\")\n",
        "            \n",
        "        elif 'news' in statement:\n",
        "            news = webbrowser.open_new_tab(\"https://timesofindia.indiatimes.com/home/headlines\")\n",
        "            speak('Here are some headlines from the Times of India,Happy reading')\n",
        "            time.sleep(6)\n",
        "\n",
        "#         elif \"camera\" in statement or \"take a photo\" in statement:\n",
        "#             ec.capture(0,\"robo camera\",\"img.jpg\")\n",
        "\n",
        "        elif 'search'  in statement:\n",
        "            statement = statement.replace(\"search\", \"\")\n",
        "            webbrowser.open_new_tab(statement)\n",
        "            time.sleep(5)\n",
        "#         elif 'ask' in statement:\n",
        "#             speak('I can answer to computational and geographical questions  and what question do you want to ask now')\n",
        "#             question=takeCommand()\n",
        "#             app_id=\"Paste your unique ID here \"\n",
        "#             client = wolframalpha.Client('R2K75H-7ELALHR35X')\n",
        "#             res = client.query(question)\n",
        "#             answer = next(res.results).text\n",
        "#             speak(answer)\n",
        "#             print(answer)\n",
        "        elif 'who are you' in statement or 'what can you do' in statement:\n",
        "            speak('I am Ashhhh version 1 point O your personal assistant. I am programmed to minor tasks like'\n",
        "                  'opening youtube,google chrome, gmail and stackoverflow ,predict time,take a photo,search wikipedia,predict weather' \n",
        "                  'In different cities, get top headline news from times of india and you can ask me computational or geographical questions too!')\n",
        "\n",
        "\n",
        "        elif \"who made you\" in statement or \"who created you\" in statement or \"who discovered you\" in statement:\n",
        "            speak(\"I was built by a developer\")\n",
        "            print(\"I was built by a developer\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Listening...\n",
            "<class 'speech_recognition.Microphone'>\n",
            "user said:who are you\n",
            "\n",
            "Listening...\n",
            "<class 'speech_recognition.Microphone'>\n",
            "user said:Kabaddi\n",
            "\n",
            "Listening...\n",
            "<class 'speech_recognition.Microphone'>\n",
            "user said:who created you\n",
            "\n",
            "I was built by Amar\n",
            "Listening...\n",
            "<class 'speech_recognition.Microphone'>\n",
            "Listening...\n",
            "<class 'speech_recognition.Microphone'>\n",
            "Listening...\n",
            "<class 'speech_recognition.Microphone'>\n",
            "Listening...\n",
            "<class 'speech_recognition.Microphone'>\n",
            "Listening...\n",
            "<class 'speech_recognition.Microphone'>\n",
            "Listening...\n",
            "<class 'speech_recognition.Microphone'>\n",
            "Listening...\n",
            "<class 'speech_recognition.Microphone'>\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[1;32m<ipython-input-109-ca01a8b98239>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[1;32mwhile\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m         \u001b[0mspeak\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Tell me how can I help you now?\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m         \u001b[0mstatement\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtakeCommand\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mstatement\u001b[0m\u001b[1;33m==\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m             \u001b[1;32mcontinue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32m<ipython-input-103-65bb46542b48>\u001b[0m in \u001b[0;36mtakeCommand\u001b[1;34m()\u001b[0m\n\u001b[0;32m      4\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Listening...\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msource\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m         \u001b[0maudio\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlisten\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msource\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32mc:\\users\\amarendramahapatra\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\speech_recognition\\__init__.py\u001b[0m in \u001b[0;36mlisten\u001b[1;34m(self, source, timeout, phrase_time_limit, snowboy_configuration)\u001b[0m\n\u001b[0;32m    650\u001b[0m                     \u001b[1;32mbreak\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    651\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 652\u001b[1;33m                 \u001b[0mbuffer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msource\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstream\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msource\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mCHUNK\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    653\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbuffer\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;32mbreak\u001b[0m  \u001b[1;31m# reached end of the stream\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    654\u001b[0m                 \u001b[0mframes\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbuffer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32mc:\\users\\amarendramahapatra\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\speech_recognition\\__init__.py\u001b[0m in \u001b[0;36mread\u001b[1;34m(self, size)\u001b[0m\n\u001b[0;32m    159\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    160\u001b[0m         \u001b[1;32mdef\u001b[0m \u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msize\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 161\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpyaudio_stream\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msize\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mexception_on_overflow\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    162\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    163\u001b[0m         \u001b[1;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32mc:\\users\\amarendramahapatra\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\pyaudio.py\u001b[0m in \u001b[0;36mread\u001b[1;34m(self, num_frames, exception_on_overflow)\u001b[0m\n\u001b[0;32m    606\u001b[0m                           paCanNotReadFromAnOutputOnlyStream)\n\u001b[0;32m    607\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 608\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mpa\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_stream\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stream\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnum_frames\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mexception_on_overflow\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    609\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    610\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mget_read_available\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zC7o9UfuDVKu"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8h3--hxhDVKx"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}